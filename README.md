# BetAI-Local AI Face-Swap (Next.js + FastAPI + InsightFace)

Real-time **face-swap** demo: Next.js frontend + FastAPI backend using **InsightFace** and ONNX model `inswapper_128.onnx`.

![Demo preview](public/video.gif)
Camera â†’ JPEG frames via WebSocket â†’ backend â†’ swapped JPEGs back â†’ rendered live.

> âš ï¸ The model file (`inswapper_128.onnx`) is **not** included in Git. Place it manually under `backend/models/`.

---

## ğŸ“¦ Project Structure

```
.
â”œâ”€ app/                     # Next.js (App Router)
â”‚  â””â”€ page.tsx             # Frontend logic (camera, WS stream, recorder, reference preview)
â”œâ”€ backend/
â”‚  â”œâ”€ app.py               # FastAPI: upload, reference info, WS processing, watermark overlay
â”‚  â””â”€ models/
â”‚     â””â”€ inswapper_128.onnx  # <-- Put your ONNX model here
â”œâ”€ .gitignore
â””â”€ README.md
```

---

## âœ… Requirements

- Node.js 18+
- Python 3.10+ (3.11 recommended)
- Git
- (Optional GPU) CUDA 12.x + cuDNN for `onnxruntime-gpu`

---

## âš™ï¸ Environment Variables

Create a `.env.local` in the root of the repo:

```bash
NEXT_PUBLIC_BACKEND_WS=ws://127.0.0.1:8000/ws
NEXT_PUBLIC_BACKEND_UPLOAD=http://127.0.0.1:8000/upload-reference
```

---

## ğŸ§© Backend (FastAPI)

1. Create and activate a virtual environment:
```powershell
cd backend
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

2. Install dependencies (CPU version):
```powershell
pip install --upgrade pip
pip install fastapi uvicorn numpy opencv-python insightface onnxruntime
```

> ğŸ’¡ For GPU:
> ```powershell
> pip uninstall -y onnxruntime
> pip install onnxruntime-gpu
> ```
> Then verify:
> ```powershell
> python -c "import onnxruntime as ort; print(ort.get_available_providers())"
> ```
> You should see `'CUDAExecutionProvider'` in the list.

3. Copy the model file:
```powershell
mkdir models
# Place your inswapper_128.onnx in backend/models/
```

4. Run the backend:
```powershell
uvicorn backend.app:app --host 127.0.0.1 --port 8000 --reload
```

---

## ğŸŒ Frontend (Next.js)

From the repo root:

```powershell
npm install
npm run dev
```

Then open: [http://localhost:3000](http://localhost:3000)

---

## â–¶ï¸ Usage

1. Click **"Upload reference"** and select a face image.  
2. Click **"Start camera"**, then **"Connect WS"**.  
3. The live camera stream is processed and faces are swapped in real time.  
4. You can start **recording** and download the `.webm` file afterward.  
5. The reference thumbnail is displayed in the UI for clarity.

---

## ğŸ§  Main Endpoints

| Method | URL | Description |
|--------|-----|-------------|
| `POST` | `/upload-reference` | Upload reference image |
| `GET` | `/reference-thumb` | Get the current reference thumbnail |
| `GET` | `/reference-info` | Get reference metadata |
| `WS` | `/ws` | Live JPEG frame streaming + swap response |

---

## âš¡ Performance Tips

### CPU
- Reduce resolution to `640Ã—360` for smoother FPS.  
- In `app.py`, tweak:
  ```python
  det_size=(384,384)
  DETECT_EVERY = 6
  ```
- JPEG quality `0.65â€“0.75` is a good balance.

### GPU
- Use `onnxruntime-gpu` + CUDA 12.x.  
- You can increase detector size for more accuracy (`512Ã—512` or `640Ã—640`).

---

## ğŸ§° Troubleshooting

### âŒ `FileNotFoundError: inswapper_128.onnx should exist`
â†’ Model not found â€” ensure itâ€™s in `backend/models/inswapper_128.onnx`.

### âŒ `cublasLt64_12.dll missing`
â†’ CUDA Toolkit 12.x not installed or not added to PATH.  
Check:
```powershell
python -c "import onnxruntime as ort; print(ort.get_available_providers())"
```

### âŒ Camera doesnâ€™t start
â†’ Grant browser camera permission (HTTPS required in some browsers).

---

## ğŸš€ Quick Start

1ï¸âƒ£ Clone repo  
2ï¸âƒ£ Copy `inswapper_128.onnx` â†’ `backend/models/`  
3ï¸âƒ£ Install dependencies (`pip`, `npm`)  
4ï¸âƒ£ Start backend â†’ `uvicorn backend.app:app --reload`  
5ï¸âƒ£ Start frontend â†’ `npm run dev`  
6ï¸âƒ£ Open [http://localhost:3000](http://localhost:3000)  
7ï¸âƒ£ Upload reference â†’ Start camera â†’ Connect WS â†’ ğŸ‰

---
